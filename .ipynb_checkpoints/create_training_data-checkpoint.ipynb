{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "patent_descriptions_df = pd.read_csv(\"patent_descriptions.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 968 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JasonKatz/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (8,9,11,12,13,14,15,16,17,19,20,21,22,23,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "decisions_df = pd.read_csv(\"ptab2_decisions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "proceedings_df = pd.read_csv(\"ptab2_proceedings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.5 ms\n"
     ]
    }
   ],
   "source": [
    "ignore_categories = ['Administrative Remand', 'Affirmed', 'Affirmed and Remanded', 'Affirmed with New Ground of Rejection   ', \n",
    "                'Affirmed with new ground of rejection   ', 'Affirmed-in-Part', 'Affirmed-in-Part and Remanded', \n",
    "                'Affirmed-in-part and remanded with new ground of rejection   ', 'Affirmed-in-part with new ground of rejection  ', \n",
    "                'Inter partes reexam affirmed', 'Inter partes reexam affirmed-in-part', 'Inter partes reexam new ground of rejection', \n",
    "                'Inter partes reexam rehearing decision is a new decision', 'Inter partes reexam remand ', 'Inter partes reexam reversed', \n",
    "                'Panel Remand', 'Reexam affirmed', 'Reexam affirmed-in-part', 'Reexam affirmed-in-part with new ground of rejection  ', \n",
    "                'Reexam rehearing decision final and appealable', 'Reexam rehearing decision is a new decision', 'Reexam reversed', \n",
    "                'Request for Adverse Judgment after Institution', 'Request for Adverse Judgment before Institution', 'Reversed', \n",
    "                'Reversed and Remanded', 'Reversed with New Ground of Rejection  ', 'Reversed with new ground of rejection  ', 'Vacated', \n",
    "                'Vacated and Remanded', 'Vacated with new ground of rejection   ', 'Vacated-in-Part', 'Termination']\n",
    "\n",
    "good_claim_categories = ['Denied (Patent Owner)', 'Final Decision', 'Final decision', 'Granted', 'Granted (Patent Owner)', 'Granted (Petitioner)', \n",
    "                         'Granted-In-Part', 'Granted-in-Part (Patent Owner)', 'Granted-in-Part (Petitioner)', 'Settlement', 'Settlement after Institution', \n",
    "                         'Dismissed after Institution']\n",
    "\n",
    "bad_claim_categories = ['Decision on Petition - Denied', 'Denied (Petitioner)', 'Dismissed', 'Dismissed before Institution', \n",
    "                        'Institution Denied', 'Settlement before Institution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions_df = decisions_df[~decisions_df['subdecision_type_category'].isin(ignore_categories)]\n",
    "\n",
    "decisions_df['good_claim'] = decisions_df['subdecision_type_category'].isin(good_claim_categories).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 315 ms\n"
     ]
    }
   ],
   "source": [
    "proceedings_df['accorded_filing_date'] = pd.to_datetime(proceedings_df['accorded_filing_date'], errors='coerce')\n",
    "proceedings_df['respondent_grant_date'] = pd.to_datetime(proceedings_df['respondent_grant_date'], errors='coerce')\n",
    "proceedings_df = proceedings_df[proceedings_df['accorded_filing_date'].between('1800-01-01', pd.datetime.today())]\n",
    "proceedings_df = proceedings_df[proceedings_df['respondent_grant_date'].between('1800-01-01', pd.datetime.today())]\n",
    "proceedings_df['days_between_grant_and_filing'] = (proceedings_df['accorded_filing_date'] - proceedings_df['respondent_grant_date']).dt.days.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.89 ms\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "training_data['proceeding_number'] = decisions_df['proceeding_number']\n",
    "training_data['patent_id'] = decisions_df['respondent_patent_number']\n",
    "training_data['good_claim'] = decisions_df['good_claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.1 ms\n"
     ]
    }
   ],
   "source": [
    "training_data = training_data.merge(patent_descriptions_df, on=\"patent_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.5 ms\n"
     ]
    }
   ],
   "source": [
    "training_data = training_data.merge(proceedings_df[['proceeding_number', 'days_between_grant_and_filing']], on=\"proceeding_number\", how=\"left\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "training_data['description_word_count'] = training_data['detailed_description'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_counts = []\n",
    "fk_scores = []\n",
    "for description in training_data['detailed_description']:\n",
    "    description = description.lower()\n",
    "    r = Readability(description.replace('aed-512', ''))\n",
    "    fk_score = r.flesch_kincaid().score\n",
    "    fk_scores.append[fk_scorea]\n",
    "    fig_counts.append(description.count(\"fig.\") + description.count(\"figs.\"))\n",
    "training_data['fig_counts'] = fig_counts\n",
    "training_data['fk_score'] = fk_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_csv(\"training_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
